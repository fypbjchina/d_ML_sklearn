{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Approximate nearest neighbors in TSNE\n",
        "\n",
        "This example presents how to chain KNeighborsTransformer and TSNE in a pipeline.\n",
        "It also shows how to wrap the packages `nmslib` and `pynndescent` to replace\n",
        "KNeighborsTransformer and perform approximate nearest neighbors. These packages\n",
        "can be installed with `pip install nmslib pynndescent`.\n",
        "\n",
        "Note: In KNeighborsTransformer we use the definition which includes each\n",
        "training point as its own neighbor in the count of `n_neighbors`, and for\n",
        "compatibility reasons, one extra neighbor is computed when `mode == 'distance'`.\n",
        "Please note that we do the same in the proposed `nmslib` wrapper.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Tom Dupre la Tour\n",
        "# License: BSD 3 clause"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First we try to import the packages and warn the user in case they are\n",
        "missing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The package 'nmslib' is required to run this example.\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'tuple' object has no attribute 'tb_frame'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnmslib\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nmslib'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe package \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnmslib\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is required to run this example.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m     sys\u001b[38;5;241m.\u001b[39mexit()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[1;31mSystemExit\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\fuy3pk\\.conda\\envs\\fyp2024\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2097\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[0;32m   2095\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2096\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m-> 2097\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mInteractiveTB\u001b[38;5;241m.\u001b[39mget_exception_only(etype,\n\u001b[0;32m   2098\u001b[0m                                                      value))\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2101\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontains_exceptiongroup\u001b[39m(val):\n",
            "File \u001b[1;32mc:\\Users\\fuy3pk\\.conda\\envs\\fyp2024\\Lib\\site-packages\\IPython\\core\\ultratb.py:710\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[0;32m    703\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \n\u001b[0;32m    705\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mstructured_traceback(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
            "File \u001b[1;32mc:\\Users\\fuy3pk\\.conda\\envs\\fyp2024\\Lib\\site-packages\\IPython\\core\\ultratb.py:568\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    565\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m    566\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    567\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 568\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructured_traceback(\n\u001b[0;32m    569\u001b[0m             etype,\n\u001b[0;32m    570\u001b[0m             evalue,\n\u001b[0;32m    571\u001b[0m             (etb, chained_exc_ids),  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    572\u001b[0m             chained_exceptions_tb_offset,\n\u001b[0;32m    573\u001b[0m             context,\n\u001b[0;32m    574\u001b[0m         )\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
            "File \u001b[1;32mc:\\Users\\fuy3pk\\.conda\\envs\\fyp2024\\Lib\\site-packages\\IPython\\core\\ultratb.py:1435\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1434\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m etb\n\u001b[1;32m-> 1435\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m FormattedTB\u001b[38;5;241m.\u001b[39mstructured_traceback(\n\u001b[0;32m   1436\u001b[0m     \u001b[38;5;28mself\u001b[39m, etype, evalue, etb, tb_offset, number_of_lines_of_context\n\u001b[0;32m   1437\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\fuy3pk\\.conda\\envs\\fyp2024\\Lib\\site-packages\\IPython\\core\\ultratb.py:1326\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1323\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[0;32m   1325\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[1;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m VerboseTB\u001b[38;5;241m.\u001b[39mstructured_traceback(\n\u001b[0;32m   1327\u001b[0m         \u001b[38;5;28mself\u001b[39m, etype, value, tb, tb_offset, number_of_lines_of_context\n\u001b[0;32m   1328\u001b[0m     )\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
            "File \u001b[1;32mc:\\Users\\fuy3pk\\.conda\\envs\\fyp2024\\Lib\\site-packages\\IPython\\core\\ultratb.py:1173\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[0;32m   1165\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1166\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1170\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   1171\u001b[0m ):\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1173\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m   1174\u001b[0m                                                            tb_offset)\n\u001b[0;32m   1176\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[0;32m   1177\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\fuy3pk\\.conda\\envs\\fyp2024\\Lib\\site-packages\\IPython\\core\\ultratb.py:1063\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m   1061\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[0;32m   1062\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1063\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_records(etb, number_of_lines_of_context, tb_offset) \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m   1064\u001b[0m )\n\u001b[0;32m   1066\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1067\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\fuy3pk\\.conda\\envs\\fyp2024\\Lib\\site-packages\\IPython\\core\\ultratb.py:1131\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[1;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1131\u001b[0m         mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(cf\u001b[38;5;241m.\u001b[39mtb_frame)\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1133\u001b[0m             mod_name \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "try:\n",
        "    import nmslib\n",
        "except ImportError:\n",
        "    print(\"The package 'nmslib' is required to run this example.\")\n",
        "    sys.exit()\n",
        "\n",
        "try:\n",
        "    from pynndescent import PyNNDescentTransformer\n",
        "except ImportError:\n",
        "    print(\"The package 'pynndescent' is required to run this example.\")\n",
        "    sys.exit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define a wrapper class for implementing the scikit-learn API to the\n",
        "`nmslib`, as well as a loading function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "class NMSlibTransformer(TransformerMixin, BaseEstimator):\n",
        "    \"\"\"Wrapper for using nmslib as sklearn's KNeighborsTransformer\"\"\"\n",
        "\n",
        "    def __init__(self, n_neighbors=5, metric=\"euclidean\", method=\"sw-graph\", n_jobs=-1):\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.method = method\n",
        "        self.metric = metric\n",
        "        self.n_jobs = n_jobs\n",
        "\n",
        "    def fit(self, X):\n",
        "        self.n_samples_fit_ = X.shape[0]\n",
        "\n",
        "        # see more metric in the manual\n",
        "        # https://github.com/nmslib/nmslib/tree/master/manual\n",
        "        space = {\n",
        "            \"euclidean\": \"l2\",\n",
        "            \"cosine\": \"cosinesimil\",\n",
        "            \"l1\": \"l1\",\n",
        "            \"l2\": \"l2\",\n",
        "        }[self.metric]\n",
        "\n",
        "        self.nmslib_ = nmslib.init(method=self.method, space=space)\n",
        "        self.nmslib_.addDataPointBatch(X.copy())\n",
        "        self.nmslib_.createIndex()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        n_samples_transform = X.shape[0]\n",
        "\n",
        "        # For compatibility reasons, as each sample is considered as its own\n",
        "        # neighbor, one extra neighbor will be computed.\n",
        "        n_neighbors = self.n_neighbors + 1\n",
        "\n",
        "        if self.n_jobs < 0:\n",
        "            # Same handling as done in joblib for negative values of n_jobs:\n",
        "            # in particular, `n_jobs == -1` means \"as many threads as CPUs\".\n",
        "            num_threads = joblib.cpu_count() + self.n_jobs + 1\n",
        "        else:\n",
        "            num_threads = self.n_jobs\n",
        "\n",
        "        results = self.nmslib_.knnQueryBatch(\n",
        "            X.copy(), k=n_neighbors, num_threads=num_threads\n",
        "        )\n",
        "        indices, distances = zip(*results)\n",
        "        indices, distances = np.vstack(indices), np.vstack(distances)\n",
        "\n",
        "        indptr = np.arange(0, n_samples_transform * n_neighbors + 1, n_neighbors)\n",
        "        kneighbors_graph = csr_matrix(\n",
        "            (distances.ravel(), indices.ravel(), indptr),\n",
        "            shape=(n_samples_transform, self.n_samples_fit_),\n",
        "        )\n",
        "\n",
        "        return kneighbors_graph\n",
        "\n",
        "\n",
        "def load_mnist(n_samples):\n",
        "    \"\"\"Load MNIST, shuffle the data, and return only n_samples.\"\"\"\n",
        "    mnist = fetch_openml(\"mnist_784\", as_frame=False)\n",
        "    X, y = shuffle(mnist.data, mnist.target, random_state=2)\n",
        "    return X[:n_samples] / 255, y[:n_samples]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We benchmark the different exact/approximate nearest neighbors transformers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.neighbors import KNeighborsTransformer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "datasets = [\n",
        "    (\"MNIST_10000\", load_mnist(n_samples=10_000)),\n",
        "    (\"MNIST_20000\", load_mnist(n_samples=20_000)),\n",
        "]\n",
        "\n",
        "n_iter = 500\n",
        "perplexity = 30\n",
        "metric = \"euclidean\"\n",
        "# TSNE requires a certain number of neighbors which depends on the\n",
        "# perplexity parameter.\n",
        "# Add one since we include each sample as its own neighbor.\n",
        "n_neighbors = int(3.0 * perplexity + 1) + 1\n",
        "\n",
        "tsne_params = dict(\n",
        "    init=\"random\",  # pca not supported for sparse matrices\n",
        "    perplexity=perplexity,\n",
        "    method=\"barnes_hut\",\n",
        "    random_state=42,\n",
        "    n_iter=n_iter,\n",
        "    learning_rate=\"auto\",\n",
        ")\n",
        "\n",
        "transformers = [\n",
        "    (\n",
        "        \"KNeighborsTransformer\",\n",
        "        KNeighborsTransformer(n_neighbors=n_neighbors, mode=\"distance\", metric=metric),\n",
        "    ),\n",
        "    (\n",
        "        \"NMSlibTransformer\",\n",
        "        NMSlibTransformer(n_neighbors=n_neighbors, metric=metric),\n",
        "    ),\n",
        "    (\n",
        "        \"PyNNDescentTransformer\",\n",
        "        PyNNDescentTransformer(\n",
        "            n_neighbors=n_neighbors, metric=metric, parallel_batch_queries=True\n",
        "        ),\n",
        "    ),\n",
        "]\n",
        "\n",
        "for dataset_name, (X, y) in datasets:\n",
        "    msg = f\"Benchmarking on {dataset_name}:\"\n",
        "    print(f\"\\n{msg}\\n\" + str(\"-\" * len(msg)))\n",
        "\n",
        "    for transformer_name, transformer in transformers:\n",
        "        longest = np.max([len(name) for name, model in transformers])\n",
        "        start = time.time()\n",
        "        transformer.fit(X)\n",
        "        fit_duration = time.time() - start\n",
        "        print(f\"{transformer_name:<{longest}} {fit_duration:.3f} sec (fit)\")\n",
        "        start = time.time()\n",
        "        Xt = transformer.transform(X)\n",
        "        transform_duration = time.time() - start\n",
        "        print(f\"{transformer_name:<{longest}} {transform_duration:.3f} sec (transform)\")\n",
        "        if transformer_name == \"PyNNDescentTransformer\":\n",
        "            start = time.time()\n",
        "            Xt = transformer.transform(X)\n",
        "            transform_duration = time.time() - start\n",
        "            print(\n",
        "                f\"{transformer_name:<{longest}} {transform_duration:.3f} sec\"\n",
        "                \" (transform)\"\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sample output::\n",
        "\n",
        "    Benchmarking on MNIST_10000:\n",
        "    ----------------------------\n",
        "    KNeighborsTransformer  0.007 sec (fit)\n",
        "    KNeighborsTransformer  1.139 sec (transform)\n",
        "    NMSlibTransformer      0.208 sec (fit)\n",
        "    NMSlibTransformer      0.315 sec (transform)\n",
        "    PyNNDescentTransformer 4.823 sec (fit)\n",
        "    PyNNDescentTransformer 4.884 sec (transform)\n",
        "    PyNNDescentTransformer 0.744 sec (transform)\n",
        "\n",
        "    Benchmarking on MNIST_20000:\n",
        "    ----------------------------\n",
        "    KNeighborsTransformer  0.011 sec (fit)\n",
        "    KNeighborsTransformer  5.769 sec (transform)\n",
        "    NMSlibTransformer      0.733 sec (fit)\n",
        "    NMSlibTransformer      1.077 sec (transform)\n",
        "    PyNNDescentTransformer 14.448 sec (fit)\n",
        "    PyNNDescentTransformer 7.103 sec (transform)\n",
        "    PyNNDescentTransformer 1.759 sec (transform)\n",
        "\n",
        "Notice that the `PyNNDescentTransformer` takes more time during the first\n",
        "`fit` and the first `transform` due to the overhead of the numba just in time\n",
        "compiler. But after the first call, the compiled Python code is kept in a\n",
        "cache by numba and subsequent calls do not suffer from this initial overhead.\n",
        "Both :class:`~sklearn.neighbors.KNeighborsTransformer` and `NMSlibTransformer`\n",
        "are only run once here as they would show more stable `fit` and `transform`\n",
        "times (they don't have the cold start problem of PyNNDescentTransformer).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import NullFormatter\n",
        "\n",
        "transformers = [\n",
        "    (\"TSNE with internal NearestNeighbors\", TSNE(metric=metric, **tsne_params)),\n",
        "    (\n",
        "        \"TSNE with KNeighborsTransformer\",\n",
        "        make_pipeline(\n",
        "            KNeighborsTransformer(\n",
        "                n_neighbors=n_neighbors, mode=\"distance\", metric=metric\n",
        "            ),\n",
        "            TSNE(metric=\"precomputed\", **tsne_params),\n",
        "        ),\n",
        "    ),\n",
        "    (\n",
        "        \"TSNE with NMSlibTransformer\",\n",
        "        make_pipeline(\n",
        "            NMSlibTransformer(n_neighbors=n_neighbors, metric=metric),\n",
        "            TSNE(metric=\"precomputed\", **tsne_params),\n",
        "        ),\n",
        "    ),\n",
        "]\n",
        "\n",
        "# init the plot\n",
        "nrows = len(datasets)\n",
        "ncols = np.sum([1 for name, model in transformers if \"TSNE\" in name])\n",
        "fig, axes = plt.subplots(\n",
        "    nrows=nrows, ncols=ncols, squeeze=False, figsize=(5 * ncols, 4 * nrows)\n",
        ")\n",
        "axes = axes.ravel()\n",
        "i_ax = 0\n",
        "\n",
        "for dataset_name, (X, y) in datasets:\n",
        "    msg = f\"Benchmarking on {dataset_name}:\"\n",
        "    print(f\"\\n{msg}\\n\" + str(\"-\" * len(msg)))\n",
        "\n",
        "    for transformer_name, transformer in transformers:\n",
        "        longest = np.max([len(name) for name, model in transformers])\n",
        "        start = time.time()\n",
        "        Xt = transformer.fit_transform(X)\n",
        "        transform_duration = time.time() - start\n",
        "        print(\n",
        "            f\"{transformer_name:<{longest}} {transform_duration:.3f} sec\"\n",
        "            \" (fit_transform)\"\n",
        "        )\n",
        "\n",
        "        # plot TSNE embedding which should be very similar across methods\n",
        "        axes[i_ax].set_title(transformer_name + \"\\non \" + dataset_name)\n",
        "        axes[i_ax].scatter(\n",
        "            Xt[:, 0],\n",
        "            Xt[:, 1],\n",
        "            c=y.astype(np.int32),\n",
        "            alpha=0.2,\n",
        "            cmap=plt.cm.viridis,\n",
        "        )\n",
        "        axes[i_ax].xaxis.set_major_formatter(NullFormatter())\n",
        "        axes[i_ax].yaxis.set_major_formatter(NullFormatter())\n",
        "        axes[i_ax].axis(\"tight\")\n",
        "        i_ax += 1\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sample output::\n",
        "\n",
        "    Benchmarking on MNIST_10000:\n",
        "    ----------------------------\n",
        "    TSNE with internal NearestNeighbors 24.828 sec (fit_transform)\n",
        "    TSNE with KNeighborsTransformer     20.111 sec (fit_transform)\n",
        "    TSNE with NMSlibTransformer         21.757 sec (fit_transform)\n",
        "\n",
        "    Benchmarking on MNIST_20000:\n",
        "    ----------------------------\n",
        "    TSNE with internal NearestNeighbors 51.955 sec (fit_transform)\n",
        "    TSNE with KNeighborsTransformer     50.994 sec (fit_transform)\n",
        "    TSNE with NMSlibTransformer         43.536 sec (fit_transform)\n",
        "\n",
        "We can observe that the default :class:`~sklearn.manifold.TSNE` estimator with\n",
        "its internal :class:`~sklearn.neighbors.NearestNeighbors` implementation is\n",
        "roughly equivalent to the pipeline with :class:`~sklearn.manifold.TSNE` and\n",
        ":class:`~sklearn.neighbors.KNeighborsTransformer` in terms of performance.\n",
        "This is expected because both pipelines rely internally on the same\n",
        ":class:`~sklearn.neighbors.NearestNeighbors` implementation that performs\n",
        "exacts neighbors search. The approximate `NMSlibTransformer` is already\n",
        "slightly faster than the exact search on the smallest dataset but this speed\n",
        "difference is expected to become more significant on datasets with a larger\n",
        "number of samples.\n",
        "\n",
        "Notice however that not all approximate search methods are guaranteed to\n",
        "improve the speed of the default exact search method: indeed the exact search\n",
        "implementation significantly improved since scikit-learn 1.1. Furthermore, the\n",
        "brute-force exact search method does not require building an index at `fit`\n",
        "time. So, to get an overall performance improvement in the context of the\n",
        ":class:`~sklearn.manifold.TSNE` pipeline, the gains of the approximate search\n",
        "at `transform` need to be larger than the extra time spent to build the\n",
        "approximate search index at `fit` time.\n",
        "\n",
        "Finally, the TSNE algorithm itself is also computationally intensive,\n",
        "irrespective of the nearest neighbors search. So speeding-up the nearest\n",
        "neighbors search step by a factor of 5 would not result in a speed up by a\n",
        "factor of 5 for the overall pipeline.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
